% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RD_lp.R
\name{RDHonest}
\alias{RDHonest}
\title{Honest inference in RD}
\usage{
RDHonest(formula, data, subset, weights, cutoff = 0, M,
  kern = "triangular", na.action, opt.criterion, bw.equal = TRUE, h,
  se.method = "nn", alpha = 0.05, beta = 0.8, J = 3,
  sclass = "H", order = 1, se.initial = "EHW")
}
\arguments{
\item{formula}{object of class \code{"formula"} (or one that can be coerced
to that class) of the form \code{outcome ~ running_variable}}

\item{data}{optional data frame, list or environment (or object coercible by
\code{as.data.frame} to a data frame) containing the outcome and running
variables in the model. If not found in \code{data}, the variables are
taken from \code{environment(formula)}, typically the environment from
which the function is called.}

\item{subset}{optional vector specifying a subset of observations to be used
in the fitting process.}

\item{weights}{Optional vector of weights to weight the observations
(useful for aggregated data). Disregarded if optimal kernel is used.}

\item{cutoff}{specifies the RD cutoff in the running variable.}

\item{M}{Bound on second derivative of the conditional mean function.}

\item{kern}{specifies kernel function used in the local regression. It can
either be a string equal to \code{"triangular"} (\eqn{k(u)=(1-|u|)_{+}}),
\code{"epanechnikov"} (\eqn{k(u)=(3/4)(1-u^2)_{+}}), or \code{"uniform"}
(\eqn{k(u)= (|u|<1)/2}), or else a kernel function.}

\item{na.action}{function which indicates what should happen when the data
contain \code{NA}s. The default is set by the \code{na.action} setting of
\code{options} (usually \code{na.omit}).}

\item{opt.criterion}{Optimality criterion that bandwidth is designed to
    optimize. The options are:

   \describe{

   \item{\code{"MSE"}}{Finite-sample maximum MSE}

   \item{\code{"FLCI"}}{Length of (fixed-length) two-sided
       confidence intervals.}

   \item{\code{"OCI"}}{Given quantile of excess length of one-sided
       confidence intervals}

    }

    The methods use conditional variance given by \code{sigma2}, if supplied.
    Otherwise, for the purpose of estimating the optimal bandwidth,
    conditional variance is estimated using the method specified by
    \code{se.initial}.}

\item{bw.equal}{logical specifying whether bandwidths on either side of
cutoff should be constrained to equal to each other.}

\item{h}{bandwidth, a scalar parameter. For fuzzy or sharp RD, it can be a
named vector of length two with names \code{"p"} and \code{"m"}, in which
case the bandwidth \code{h["m"]} is used for observations below the
cutoff, and the bandwidth \code{h["p"]} is used for observations above
the cutoff. If not supplied, optimal bandwidth is computed according to
criterion given by \code{opt.criterion}.}

\item{se.method}{Vector with methods for estimating standard error of
estimate. If \code{NULL}, standard errors are not computed. The elements of
the vector can consist of the following methods:

\describe{
    \item{"nn"}{Nearest neighbor method}

    \item{"EHW"}{Eicker-Huber-White, with residuals from local regression
    (local polynomial estimators only).}

    \item{"demeaned"}{Like EHW, but instead of using the regression
        residuals, estimate \eqn{\sigma^2_i}{sigma^2_i} by subtracting the
        estimated intercept from the outcome (and not subtracting the
        estimated slope). Local polynomial estimators only.}

   \item{"plugin"}{Plug-in estimate based on asymptotic variance. Local
        polynomial estimators in sharp RD only.}

   \item{"supplied.var"}{Use conditional variance supplied by \code{sigma2} or
        \code{d} instead of computing residuals}

}}

\item{alpha}{determines confidence level, \code{1-alpha} for
constructing/optimizing confidence intervals.}

\item{beta}{Determines quantile of excess length to optimize, if bandwidth
optimizes given quantile of excess length of one-sided confidence
intervals; otherwise ignored.}

\item{J}{Number of nearest neighbors, if "nn" is specified in
\code{se.method}.}

\item{sclass}{Smoothness class, either \code{"T"} for Taylor or
\code{"H"} for Hölder class.}

\item{order}{Order of local regression 1 for linear, 2 for quadratic.}

\item{se.initial}{Method for estimating initial variance for computing
    optimal bandwidth. Except for \code{"nn"}, all methods assume
    homoskedasticity on either side of cutoff (for RD), or for all data (for
    inference at a point).

\describe{

\item{"EHW"}{Based on residuals from a local linear regression using a
            triangular kernel, and and bandwidth given by a rule-of-thumb
            bandwidth (for inference at a point, see \code{\link{ROTBW.fit}}),
            or IK bandwidth (for fuzzy and sharp RD, see
            \code{\link{IKBW.fit}}). For fuzzy RD, the IK bandwidth is based
            on the reduced-form regression.}

\item{"demeaned"}{Like EHW, but instead of using the regression residuals,
            estimate \eqn{\sigma^2_i}{sigma^2_i} by subtracting the estimated
            intercept from the outcome (and not subtracting the estimated
            slope). }

\item{"Silverman"}{Use residuals from local constant regression with uniform
kernel and bandwidth selected using Silverman's rule of thumb, as in Equation
(14) in Imbens and Kalyanaraman (2012)}
\item{"SilvermanNN"}{Use Silverman's rule of thumb to pick the bandwidth, but
use nearest neighbor estimates, rather than the residuals.}

\item{"nn"}{Use nearest neighbor estimates, without assuming homoskedasticity}
}}
}
\value{
Returns an object of class \code{"NPRResults"}. The function
    \code{print} can be used to obtain and print a summary of the results. An
    object of class \code{"NPRResults"} is a list containing the following
    components

    \describe{
  \item{\code{estimate}}{Point estimate. This estimate is MSE-optimal if
                  \code{opt.criterion="MSE"}}

  \item{\code{lff}}{Least favorable function, only relevant for optimal estimator
             under Taylor class.}

  \item{\code{maxbias}}{Maximum bias of \code{estimate}}

  \item{\code{sd}}{Standard deviation of estimate}

  \item{\code{lower}, \code{upper}}{Lower (upper) end-point of a one-sided CI
        based on \code{estimate}. This CI is optimal if
        \code{opt.criterion=="OCI"}}

  \item{\code{hl}}{Half-length of a two-sided CI based on \code{estimate}, so
            that the CI is given by \code{c(estimate-hl, estimate+hl)}. The
            CI is optimal if \code{opt.criterion="FLCI"}}

  \item{\code{eff.obs}}{Effective number of observations used by
            \code{estimate}}

  \item{\code{hp}, \code{hm}}{Bandwidths used above and below the cutoff}

  \item{\code{naive}}{Coverage of CI that ignores bias and uses
               \code{qnorm(1-alpha/2)} as critical value}

  \item{\code{call}}{the matched call}

  \item{\code{fs}}{Not relevant for sharp RD}

}
}
\description{
Calculate estimators and one- and two-sided CIs based on local polynomial
estimator in RD under second-order Taylor or Hölder smoothness class. If
\code{kern="optimal"}, calculate optimal estimators under second-order Taylor
smoothness class.
}
\details{
The bandwidth is calculated to be optimal for a given performance criterion,
as specified by \code{opt.criterion}. For local polynomial estimators, this
optimal bandwidth is calculated using the function \code{\link{RDOptBW}}.
Alternatively, for local polynomial estimators, the bandwidths above and
below the cutoff can be specified by \code{h}.
}
\section{Note}{

\code{subset} is evaluated in the same way as variables in \code{formula},
that is first in \code{data} and then in the environment of \code{formula}.
}

\examples{

# Lee dataset
RDHonest(voteshare ~ margin, data = lee08, kern = "uniform", M = 0.1,
         h = 10, sclass = "T")
}
\references{
{

\cite{Armstrong, Tim, and Michal Kolesár. 2018. "Optimal Inference in a Class
of Regression Models." Econometrica 86 (2): 655–83.}

\cite{Armstrong, Timothy B., and Michal Kolesár. 2019.
"Simple and Honest Confidence Intervals in Nonparametric Regression", arXiv:
1606.01200.}

\cite{Imbens, Guido, and Kalyanaraman, Karthik,
"Optimal bandwidth choice for the regression discontinuity estimator." The
Review of Economic Studies 79 (3): 933-959.}

\cite{Kolesár, Michal, and Christoph Rothe. 2018. "Inference in Regression
Discontinuity Designs with a Discrete Running Variable." American Economic
Review 108 (8): 2277–2304.}
}
}
\seealso{
\code{\link{RDOptBW}}
}
